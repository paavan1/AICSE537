\documentclass[11pt]{article}
\usepackage{amsfonts,amsmath,amssymb,graphicx,url}
\usepackage{fullpage}
\usepackage{amsthm}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{wrapfig}

\author{Paavan Kumar}

\title{CSE537  Artificial Intelligence}

\setlength{\oddsidemargin}{.25in}
\setlength{\evensidemargin}{.25in}
\setlength{\textwidth}{6.25in}
\setlength{\topmargin}{-0.4in}
\setlength{\textheight}{8.5in}

\newcommand{\heading}[5]{
   \renewcommand{\thepage}{\arabic{page}}
   \noindent
   \begin{center}
   \framebox{
      \vbox{
    \hbox to 6.2in { {\bf CSE537  Artificial Intelligence}
     	 \hfill #2 }
       \vspace{4mm}
       \hbox to 6.2in { {\Large \hfill #5  \hfill} }
       \vspace{2mm}
       \hbox to 6.2in { { #3 \hfill #4} }
      }
   }
   \end{center}
   \vspace*{4mm}
}

\newcommand{\handout}[3]{\heading{#1}{#2}{\it Paavan Kumar Sirigiri, 109596437  Vivek Pradhan,         Varsha Paidi}{}{#3}}

\setlength{\parindent}{0in}
\setlength{\parskip}{0.1in}



\begin{document}
\handout{1}{\today}{Project 1 report}
\section{Implementation}
{\bf Q 1 to Q4 :}
\\\\ A generic algorithm which returns the list of actions to reach the goal has been implemented for all the search strategies.  Parentnode State   is stored in the dictionary of explored nodes. This information of  parent node states is used to trace the path  from the start state to the goal state. Each search strategy differs in data structure that is used to maintain the fringe or the frontier. Depth first search uses stack, Breadth first search uses queue, Uniform cost search uses priority queue, A star uses Priority Queue with function as their respective data structures. 


{\bf Q5:}

 State has been chosen to be  tuple  of  (coordinates, unvisitedcorners). When the number of unvisited corners is zero, the goal state has been reached.  

{\bf Q6:}


{\bf Q7:}



\section{Statistics}

{\bf Q 1 :}
\bgroup\obeylines

{\bf TinyMaze :}
[SearchAgent] using function depthFirstSearch
[SearchAgent] using problem type PositionSearchProblem
Path found with total cost of 10 in 0.0 seconds
Search nodes expanded: 16
Pacman emerges victorious! Score: 500
Average Score: 500.0
Scores:        500
Win Rate:      1/1 (1.00)
Record:        Win
{\bf MediumMaze :}
[SearchAgent] using function depthFirstSearch
[SearchAgent] using problem type PositionSearchProblem
Path found with total cost of 130 in 0.0 seconds
Search nodes expanded: 146
Pacman emerges victorious! Score: 380
Average Score: 380.0
Scores:        380
Win Rate:      1/1 (1.00)
Record:        Win
{\bf BigMaze :}
[SearchAgent] using function depthFirstSearch
[SearchAgent] using problem type PositionSearchProblem
Path found with total cost of 210 in 0.0 seconds
Search nodes expanded: 391
Pacman emerges victorious! Score: 300
Average Score: 300.0
Scores:        300
Win Rate:      1/1 (1.00)
Record:        Win
{\bf Q 2 :}
{\bf MediumMaze :}
[SearchAgent] using function bfs
[SearchAgent] using problem type PositionSearchProblem
Path found with total cost of 68 in 0.0 seconds
Search nodes expanded: 270
Pacman emerges victorious! Score: 442
Average Score: 442.0
Scores:        442
Win Rate:      1/1 (1.00)
Record:        Win
{\bf BigMaze :}
[SearchAgent] using function bfs
[SearchAgent] using problem type PositionSearchProblem
Path found with total cost of 210 in 0.1 seconds
Search nodes expanded: 621
Pacman emerges victorious! Score: 300
Average Score: 300.0
Scores:        300
Win Rate:      1/1 (1.00)
Record:        Win
{\bf Q 3 :}
{\bf MediumMaze :}
[SearchAgent] using function ucs
[SearchAgent] using problem type PositionSearchProblem
Path found with total cost of 68 in 0.0 seconds
Search nodes expanded: 269
Pacman emerges victorious! Score: 442
Average Score: 442.0
Scores:        442
Win Rate:      1/1 (1.00)
Record:        Win
{\bf MediumDottedMaze :}
Path found with total cost of 1 in 0.0 seconds
Search nodes expanded: 187
Pacman emerges victorious! Score: 646
Average Score: 646.0
Scores:        646
Win Rate:      1/1 (1.00)
Record:        Win
{\bf MediumScaryMaze :}
Path found with total cost of 68719479864 in 0.0 seconds
Search nodes expanded: 108
Pacman emerges victorious! Score: 418
Average Score: 418.0
Scores:        418
Win Rate:      1/1 (1.00)
Record:        Win
{\bf Q4 :}
{\bf Manhattan Heuristic :}
[SearchAgent] using function astar and heuristic manhattanHeuristic
[SearchAgent] using problem type PositionSearchProblem
Path found with total cost of 210 in 0.0 seconds
Search nodes expanded: 539
Pacman emerges victorious! Score: 300
Average Score: 300.0
Scores:        300
Win Rate:      1/1 (1.00)
Record:        Win
{\bf Null Heuristic :}
[SearchAgent] using function astar and heuristic nullHeuristic
[SearchAgent] using problem type PositionSearchProblem
Path found with total cost of 210 in 0.1 seconds
Search nodes expanded: 620
Pacman emerges victorious! Score: 300
Average Score: 300.0
Scores:        300
Win Rate:      1/1 (1.00)
Record:        Win
{\bf Q5 :}
{\bf tinyCorners :}
[SearchAgent] using function bfs
[SearchAgent] using problem type CornersProblem
Path found with total cost of 28 in 0.0 seconds
Search nodes expanded: 253
Pacman emerges victorious! Score: 512
Average Score: 512.0
Scores:        512
Win Rate:      1/1 (1.00)
Record:        Win
{\bf mediumCorners :}
[SearchAgent] using function bfs
[SearchAgent] using problem type CornersProblem
Path found with total cost of 106 in 0.4 seconds
Search nodes expanded: 1967
Pacman emerges victorious! Score: 434
Average Score: 434.0
Scores:        434
Win Rate:      1/1 (1.00)
Record:        Win
\egroup

\section{Critical Analysis}
The following observations and inferences can be made from the statistics.\\
1. BFS has expanded  a lot  of nodes  before reaching the goal state compared to DFS as DFS searches deeper nodes faster.\\

2. A-star search finds the goal state by expanding lesser number of nodes if there is a good approximation of heuristic. As observed, in Q4,  Manhattan heuristic expands very less number of nodes(539) compared to null heuristic(620) . Hence choosing a admissible and consistent heuristic that better approximates the actual distance to goal state is crucial.




\end{document}
